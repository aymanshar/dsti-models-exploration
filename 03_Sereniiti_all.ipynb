{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Sereniiti_all.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8jHCxIr9BxHMrfGf6NntS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sereniiti/models-exploration/blob/develop/Ayman/03_Sereniiti_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eu9-WFC-cJV"
      },
      "source": [
        "## working with text data \n",
        "\n",
        "1. import pandas\n",
        "2. **check if any null values**\n",
        "    >- df['words_en'].isnull().sum()\n",
        "    >- df['ratings'].isnull().sum()\n",
        "    >- *we can replace Null with 0 for specific column: df['words_en'] = df['words_en'].fillna(0)*\n",
        "    >- *or for the entire data sert : df.fillna(0)*\n",
        "3. **clean the text from any punctuations using string.punctuation**\n",
        "    >- import string\n",
        "    >- clean_text=\"\".join([c for c in text if c not in string.punctuation]) in a function\n",
        "    >- create new column in the dataset to save the cleaned data applying the clean function in the text column\n",
        "    >- df['text_clean']=df['words_en'].apply(lambda x : clean_text_punc(x))\n",
        "4. **tokenize the cleaned column ( spletting the text in to a list of words) we can use regular expression re**\n",
        "    >- import re and use re.split()\n",
        "    >- tokens=re.split('\\W+',txt) to be used removing the stopwords\n",
        "5. **remove stop words if needed**\n",
        "    >- import nltk , and download the stopwords\n",
        "    >- nltk.download('stopwords') \n",
        "    >- using the tokenized function to split the sentences to words before applying the stop words removal\n",
        "    >- using nltk.corpus.stopwords.words('english')\n",
        "    >- crate function to remove stop words [word for word in text if word not in stopwords] in a function\n",
        "    >- create new column in the dataset to save the cleaned tokenized data applying the remove stopwords function in the cleaned tokenized column\n",
        "    >- df['text_clean_nostopword']=df['text_clean'].apply(lambda x:remove_stopwords(x))\n",
        "6. **stemming the last cleaned data or lemmatization**\n",
        "    > **stemming**\n",
        "    >- stemming could stem different words meaning to one word (not correct) and also similar words meaning to different words\n",
        "    >- will use PorterStemmer from nltk\n",
        "    >- from nltk.stem import PorterStemmer , and create instance ps then use ps.stem\n",
        "     >- using the tokenized function to split the sentences to words before applying the stem words \n",
        "    >- crate function for stemming the words [ps.stem(word) for word in tokenized_txt] in a function\n",
        "    >- df['text_clean_stem']=df['text_clean'].apply(lambda x:stem_data(x))\n",
        "    \n",
        "    > **lemmatization**\n",
        "    >- same like stemming but it is doing vocabulary of words more accurate than stemming but slower and copmutitionaly expenseve\n",
        "    >- import nltk need to download nltk.download('wordnet')\n",
        "    >- using nltk.WordNetLemmatizer() then lemmatize \n",
        "    >- crate function for lemmatize the words [wn.lemmatize(word) for word in txt] in a function\n",
        "    >- df['text_clean_lemma']=df['text_clean'].apply(lambda x:lemma_data(x))\n",
        "8. **vectorization : encode text as integers to create feature vectores ( vectore of numerical feature that represent an object**\n",
        "    > **CountVectorization**\n",
        "    >- from sklearn.feature_extraction.text import CountVectorizer\n",
        "    >- create instance vectorized=CountVectorizer()\n",
        "    >- transform and fit the data column vectorize_sms=vectorized.fit_transform(df_sms['clean_sms'])\n",
        "    \n",
        "    > **n-grams** as argument in(CountVectorization, TF-IDF)\n",
        "    >- which using compination of the words at a time example 'I am learning NLP' >> 2-grams : 'I am', 'am learning', 'learning NLP' and so on same for 3-grams\n",
        "    >- create instance vectorized_n=CountVectorizer(ngram_range=(2,2))\n",
        "    >- transform and fit the data column vectorize_sms=vectorized.fit_transform(df_sms['clean_sms'])\n",
        "    \n",
        "    > **TF-IDF Vectorizer** \n",
        "    >- similar to CountVectorizer and n-gram ( cells contain weigh of how important the words) where the weigh calculated using the formula : W_i,j=tf_i,j x log(N/df_i) where tf is no. of time term i occuers in j divided total no. of terms in j (example sentence has 5 words and a word occuered 2 times in that sentence then it will be 2/5, N: count of Documents or records or lines, and df number of documents which contain the term i\n",
        "    >- **Example** j: 'I am studying NLP' >> tf_am,j for the word i=am , so tf_am,j = 1/4=0.25 (am only 1 and total no of words in j is 4), if total no of documents or record N=200, amd df_am=2 , lets calculate the weight of the word am W_am,j=0.25X(200/2)=25\n",
        "9. **text entry and testing the model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "196n3r51-eYq"
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "##!pip install -U -q PyDrive\n",
        "#from pydrive.auth import GoogleAuth\n",
        "#from pydrive.drive import GoogleDrive\n",
        "#from google.colab import auth\n",
        "#from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "#auth.authenticate_user()\n",
        "#gauth = GoogleAuth()\n",
        "#gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r3ndbRE-6J8",
        "outputId": "7579c2c0-e9a6-4086-ef46-b1255679f8b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF86dk3q-3ON"
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data_sentences.csv')\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "LREqmkUH_O22",
        "outputId": "f5d5cf79-dc9b-46f7-994d-1b6037adccb7"
      },
      "source": [
        "df.head(2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words_en</th>\n",
              "      <th>words_Fr</th>\n",
              "      <th>ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am being abused.</td>\n",
              "      <td>Je suis maltraité.</td>\n",
              "      <td>acceptable negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am unwanted.</td>\n",
              "      <td>Je suis indésirable.</td>\n",
              "      <td>acceptable negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             words_en              words_Fr              ratings\n",
              "0  I am being abused.    Je suis maltraité.  acceptable negative\n",
              "1      I am unwanted.  Je suis indésirable.  acceptable negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YzB2soq_riX",
        "outputId": "8ff2e9c4-0cf5-48b7-bcb3-ee5f3d3c9f05"
      },
      "source": [
        "# check if any null values in words_en or ratings\n",
        "print('words_en null records: ', df['words_en'].isnull().sum())\n",
        "print('ratings null records: ', df['ratings'].isnull().sum())\n",
        "#if there is any Null Value we can replace with 0\n",
        "# df['words_en'].fillna(0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "words_en null records:  0\n",
            "ratings null records:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTAqApRqlTYJ",
        "outputId": "b0f7857a-845c-4dda-c086-cca7466e7a8e"
      },
      "source": [
        "#check the unique records in ratings column to map them with code number\n",
        "df['ratings'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['acceptable negative', 'acceptable positive', 'bad', 'violent',\n",
              "       'very violent', 'good', 'excellent'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbxlWJ3SlVlM"
      },
      "source": [
        "# map the ratings to code where 0 'violent' and 1 'good'\n",
        "df['ratings_code']=df['ratings'].map({'very violent':0,'violent':0,'bad':0,'acceptable negative':1,'acceptable positive':1,'good':1,'excellent':1})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vOkyGSolbOL"
      },
      "source": [
        "# save the needed columns only in the dataset\n",
        "df=df[['words_en','ratings_code']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b98fw3VBrBZ",
        "outputId": "7ad0ac12-447d-44e4-fadc-a44c787dd2e0"
      },
      "source": [
        "# clean the text from any punctuations using string.punctuation\n",
        "import string\n",
        "print('punctuation: ',string.punctuation)\n",
        "\n",
        "# example for clean text from punctuations, we used join to join the character again after spliting\n",
        "txt='this @ is . for . trying .. to ** use ## try now'\n",
        "cleaned_txt=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "print (txt , ' \\n >> after clean: \\n', cleaned_txt)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "punctuation:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "this @ is . for . trying .. to ** use ## try now  \n",
            " >> after clean: \n",
            " this  is  for  trying  to  use  try now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUbvt2pg_78G"
      },
      "source": [
        "#create cleaning function using string.punctuation\n",
        "def clean_text_punc(txt):\n",
        "  clean_text=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "  return clean_text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY6mQWi2BGqs"
      },
      "source": [
        "# create new column with to save cleaned text\n",
        "df['text_clean']=df['words_en'].apply(lambda x : clean_text_punc(x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VY4ZAecBBbvb",
        "outputId": "e50a814b-e605-4872-e281-f444be469494"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words_en</th>\n",
              "      <th>words_Fr</th>\n",
              "      <th>ratings</th>\n",
              "      <th>ratings_code</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am being abused.</td>\n",
              "      <td>Je suis maltraité.</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I am being abused</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am unwanted.</td>\n",
              "      <td>Je suis indésirable.</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I am unwanted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I don't feel heard</td>\n",
              "      <td>Je ne me sens pas entendu</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont feel heard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I don't feel supported</td>\n",
              "      <td>Je ne me sens pas soutenue</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont feel supported</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I don't like you</td>\n",
              "      <td>Je ne t'aime pas</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont like you</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 words_en  ...             text_clean\n",
              "0      I am being abused.  ...      I am being abused\n",
              "1          I am unwanted.  ...          I am unwanted\n",
              "2      I don't feel heard  ...      I dont feel heard\n",
              "3  I don't feel supported  ...  I dont feel supported\n",
              "4       I don't like you   ...       I dont like you \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUndkvkRCAbh",
        "outputId": "6489ea5c-cc7a-4b8a-a5eb-b8f25f3877b3"
      },
      "source": [
        "#tokenize the cleaned column ( spletting the sentences in to a list of words) we can use regular expression re\n",
        "import re\n",
        "\n",
        "txt='This @ is . FOR . trying .. to ** use ## try now'\n",
        "tokens=re.split('\\W+',txt)\n",
        "tokenized_txt=[word for word in tokens]\n",
        "\n",
        "# if we need to join the words will use join\n",
        "tokenized_txt_joined=\" \".join([word for word in tokens])\n",
        "print (tokenized_txt)\n",
        "\n",
        "# we can use lower to lower the words.\n",
        "print (tokenized_txt_joined.lower())\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'FOR', 'trying', 'to', 'use', 'try', 'now']\n",
            "this is for trying to use try now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K9Qs4XfL10b"
      },
      "source": [
        "#create word tokenized function if needed\n",
        "def tokenized_aslist(txt):\n",
        "    tokens=re.split('\\W+',txt)\n",
        "    tokens=[word for word in tokens]\n",
        "    return tokens\n",
        "\n",
        "def tokenized(txt):\n",
        "    tokens=re.split('\\W+',txt)\n",
        "    tokens=\" \".join([word for word in tokens])\n",
        "    return tokens\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_iCVBPNNhyc",
        "outputId": "f8cbe5fb-1d81-433d-d699-a000707f71b2"
      },
      "source": [
        "# remove stop words if needed\n",
        "# import nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopwords=nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42Inah_GQC25",
        "outputId": "c8a1de0d-f819-4ef6-c369-ba80dad75aef"
      },
      "source": [
        "# example for stopwords \n",
        "txt_stop='This is my first test for you, are you ready?'\n",
        "# use tokenize to apply stop words by word then join all words\n",
        "tokens_stop=re.split('\\W+',txt_stop)\n",
        "text_stop=\" \".join([word for word in tokens_stop if word not in stopwords])\n",
        "print (text_stop)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This first test ready \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReJOTSCQQxJv"
      },
      "source": [
        "# create function to remove the stop words after splitting the sentences to words using re.split\n",
        "def remove_stopwords(text):\n",
        "    tokens_stop=re.split('\\W+',text)\n",
        "    text_clean=\" \".join([word for word in tokens_stop if word not in stopwords])\n",
        "    return text_clean"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aAo-C-XZCQm"
      },
      "source": [
        "# create new column for stopword cleaned text (not recommended in our case so will ignore that column)\n",
        "df['text_clean_nostopword']=df['text_clean'].apply(lambda x:remove_stopwords(x))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K-l636YhaaUN",
        "outputId": "92d2dc02-364c-44f0-bd63-8468b89206c3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words_en</th>\n",
              "      <th>words_Fr</th>\n",
              "      <th>ratings</th>\n",
              "      <th>ratings_code</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_nostopword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am being abused.</td>\n",
              "      <td>Je suis maltraité.</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I am being abused</td>\n",
              "      <td>I abused</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am unwanted.</td>\n",
              "      <td>Je suis indésirable.</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I am unwanted</td>\n",
              "      <td>I unwanted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I don't feel heard</td>\n",
              "      <td>Je ne me sens pas entendu</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont feel heard</td>\n",
              "      <td>I dont feel heard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I don't feel supported</td>\n",
              "      <td>Je ne me sens pas soutenue</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont feel supported</td>\n",
              "      <td>I dont feel supported</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I don't like you</td>\n",
              "      <td>Je ne t'aime pas</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont like you</td>\n",
              "      <td>I dont like</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 words_en  ...  text_clean_nostopword\n",
              "0      I am being abused.  ...               I abused\n",
              "1          I am unwanted.  ...             I unwanted\n",
              "2      I don't feel heard  ...      I dont feel heard\n",
              "3  I don't feel supported  ...  I dont feel supported\n",
              "4       I don't like you   ...           I dont like \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vScNzhb8afWr",
        "outputId": "ade2b2b4-e1ba-45f2-8ae4-36d7186e9c9d"
      },
      "source": [
        "# porter stemmer stemming could stem different words meaning to one word (not correct) and also similar words meaning to different words like goose and geese\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "txt_sample='I am going to be late if you are not helping '\n",
        "tokens_stem=re.split('\\W+',txt_sample)\n",
        "text_stem=\" \".join([ps.stem(word) for word in tokens_stem])\n",
        "# example \n",
        "print(text_stem)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am go to be late if you are not help \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JIL-qTmcFor"
      },
      "source": [
        "# create stemming function\n",
        "def stem_data(txt):\n",
        "    tokens_stem=re.split('\\W+',txt)\n",
        "    text=\" \".join([ps.stem(word) for word in tokens_stem])\n",
        "    return text"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdbMBCEged5m"
      },
      "source": [
        "# create new column for stemmed cleaned text\n",
        "df['text_clean_stem']=df['text_clean'].apply(lambda x:stem_data(x))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-pJXMqDaen5K",
        "outputId": "f5f8b527-fb46-4c7c-e84c-ff2ee0477c38"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words_en</th>\n",
              "      <th>words_Fr</th>\n",
              "      <th>ratings</th>\n",
              "      <th>ratings_code</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_nostopword</th>\n",
              "      <th>text_clean_stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am being abused.</td>\n",
              "      <td>Je suis maltraité.</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I am being abused</td>\n",
              "      <td>I abused</td>\n",
              "      <td>I am be abus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am unwanted.</td>\n",
              "      <td>Je suis indésirable.</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I am unwanted</td>\n",
              "      <td>I unwanted</td>\n",
              "      <td>I am unwant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I don't feel heard</td>\n",
              "      <td>Je ne me sens pas entendu</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont feel heard</td>\n",
              "      <td>I dont feel heard</td>\n",
              "      <td>I dont feel heard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I don't feel supported</td>\n",
              "      <td>Je ne me sens pas soutenue</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont feel supported</td>\n",
              "      <td>I dont feel supported</td>\n",
              "      <td>I dont feel support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I don't like you</td>\n",
              "      <td>Je ne t'aime pas</td>\n",
              "      <td>acceptable negative</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont like you</td>\n",
              "      <td>I dont like</td>\n",
              "      <td>I dont like you</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 words_en  ...      text_clean_stem\n",
              "0      I am being abused.  ...         I am be abus\n",
              "1          I am unwanted.  ...          I am unwant\n",
              "2      I don't feel heard  ...    I dont feel heard\n",
              "3  I don't feel supported  ...  I dont feel support\n",
              "4       I don't like you   ...     I dont like you \n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC2SW2sPepXU",
        "outputId": "aea11481-7902-48af-f85e-1f842b165334"
      },
      "source": [
        "# lemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmOrjFDve_vg",
        "outputId": "cc8f9b04-b621-42a6-e08c-b9d56fd5e196"
      },
      "source": [
        "# same like stemming but it is doing vocabulary of words more accurate than stemming but slower\n",
        "# example\n",
        "word_lemma =nltk.WordNetLemmatizer()\n",
        "txt_lemma_sample='I am going to be late if you are not helping '\n",
        "tokens_lemma=re.split('\\W+',txt_lemma_sample)\n",
        "text_lemma=\" \".join([ps.stem(word) for word in tokens_lemma])\n",
        "print(text_lemma)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am go to be late if you are not help \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLGx8Bk7fjTr",
        "outputId": "47534496-8ae8-4a73-fada-d6ef328936c0"
      },
      "source": [
        "# another example comparing between both\n",
        "print('===== lemmatize ======')\n",
        "print(word_lemma.lemmatize('goose'))\n",
        "print(word_lemma.lemmatize('geese')) # understand that both are same\n",
        "print('===== stem ======')\n",
        "print(ps.stem('goose'))\n",
        "print(ps.stem('geese')) # understand that both are different that is wrong"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== lemmatize ======\n",
            "goose\n",
            "goose\n",
            "===== stem ======\n",
            "goos\n",
            "gees\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQavaYD5f9Yn"
      },
      "source": [
        "# creating  function for lemmatizer\n",
        "def lemma_data(txt):\n",
        "    tokens_lemmatize=re.split('\\W+',txt)\n",
        "    text=\" \".join([word_lemma.lemmatize(word) for word in tokens_lemmatize])\n",
        "    return text"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XvsM8aQgc1n"
      },
      "source": [
        "# create new column for lemmatized cleaned text\n",
        "df['text_clean_lemma']=df['text_clean'].apply(lambda x:lemma_data(x))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q_wC0msSgkwO",
        "outputId": "b9c08a4b-6ff8-45a0-9bf0-406e35516f9f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words_en</th>\n",
              "      <th>ratings_code</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_nostopword</th>\n",
              "      <th>text_clean_stem</th>\n",
              "      <th>text_clean_lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am being abused.</td>\n",
              "      <td>1</td>\n",
              "      <td>I am being abused</td>\n",
              "      <td>I abused</td>\n",
              "      <td>I am be abus</td>\n",
              "      <td>I am being abused</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am unwanted.</td>\n",
              "      <td>1</td>\n",
              "      <td>I am unwanted</td>\n",
              "      <td>I unwanted</td>\n",
              "      <td>I am unwant</td>\n",
              "      <td>I am unwanted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I don't feel heard</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont feel heard</td>\n",
              "      <td>I dont feel heard</td>\n",
              "      <td>I dont feel heard</td>\n",
              "      <td>I dont feel heard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I don't feel supported</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont feel supported</td>\n",
              "      <td>I dont feel supported</td>\n",
              "      <td>I dont feel support</td>\n",
              "      <td>I dont feel supported</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I don't like you</td>\n",
              "      <td>1</td>\n",
              "      <td>I dont like you</td>\n",
              "      <td>I dont like</td>\n",
              "      <td>I dont like you</td>\n",
              "      <td>I dont like you</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 words_en  ...       text_clean_lemma\n",
              "0      I am being abused.  ...      I am being abused\n",
              "1          I am unwanted.  ...          I am unwanted\n",
              "2      I don't feel heard  ...      I dont feel heard\n",
              "3  I don't feel supported  ...  I dont feel supported\n",
              "4       I don't like you   ...       I dont like you \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c921IVHBgmU_"
      },
      "source": [
        "# vectorization encode a text as integers to create feature vectores ( vectore of numerical feature that represent an object)\n",
        "# CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "5XDLeXiojfwQ",
        "outputId": "25f2cb9d-3d5a-4663-b25f-02252d30408b"
      },
      "source": [
        "#example CountVectorizer\n",
        "vectorize_sample=CountVectorizer()\n",
        "\n",
        "sentences =['this is for testing counting testing training and testing',\n",
        "            'this is second word I can train and say', \n",
        "            'testing, training is very important']\n",
        "\n",
        "vectorized_data=vectorize_sample.fit(sentences)\n",
        "print(vectorized_data.vocabulary_)\n",
        "print('show get_feature_names : >> ')\n",
        "print(vectorized_data.get_feature_names())\n",
        "\n",
        "transformed_data=vectorize_sample.transform(sentences)\n",
        "print('shape: ' ,transformed_data.shape) # 3 sentences or documents and 14 words will show (3,14)\n",
        "transformed_data.toarray()\n",
        "\n",
        "# show in dataframe where header or column labels is vectorized_data.get_feature_names() and data is transformed_data.toarray()\n",
        "vect_df=pd.DataFrame(transformed_data.toarray(),columns=vectorized_data.get_feature_names())\n",
        "vect_df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 9, 'is': 5, 'for': 3, 'testing': 8, 'counting': 2, 'training': 11, 'and': 0, 'second': 7, 'word': 13, 'can': 1, 'train': 10, 'say': 6, 'very': 12, 'important': 4}\n",
            "show get_feature_names : >> \n",
            "['and', 'can', 'counting', 'for', 'important', 'is', 'say', 'second', 'testing', 'this', 'train', 'training', 'very', 'word']\n",
            "shape:  (3, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>can</th>\n",
              "      <th>counting</th>\n",
              "      <th>for</th>\n",
              "      <th>important</th>\n",
              "      <th>is</th>\n",
              "      <th>say</th>\n",
              "      <th>second</th>\n",
              "      <th>testing</th>\n",
              "      <th>this</th>\n",
              "      <th>train</th>\n",
              "      <th>training</th>\n",
              "      <th>very</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   and  can  counting  for  important  ...  this  train  training  very  word\n",
              "0    1    0         1    1          0  ...     1      0         1     0     0\n",
              "1    1    1         0    0          0  ...     1      1         0     0     1\n",
              "2    0    0         0    0          1  ...     0      0         1     1     0\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsENpDYSj1Ou"
      },
      "source": [
        "# create instance from CountVectorizer\n",
        "text_vectorized=CountVectorizer()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07rR-3dokf4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3a2004-ab88-4c1f-d74d-4f7cab348e95"
      },
      "source": [
        "# save the CountVectorized data in word_vectorized, and rating_code values in y\n",
        "word_vectorized= text_vectorized.fit_transform(df['text_clean'])\n",
        "y = df['ratings_code'].values\n",
        "print ('Word_vectorized data shape:\\n ', word_vectorized.shape,'\\n')\n",
        "# to list the vectorized words will use the instance name only first 5\n",
        "print('Text_vectorized feature names :\\n' , text_vectorized.get_feature_names()[0:5])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word_vectorized data shape:\n",
            "  (7482, 5105) \n",
            "\n",
            "Text_vectorized feature names :\n",
            " ['10', '100', '1000', '1000am', '102']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om5dCXBtspGo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split # to split our dtata set into training data and test data"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAjSvbL7stss"
      },
      "source": [
        "# define the training and test sets, 0.2 means test data is %20 of the trained data will stored in the X_test\n",
        "X_training, X_testing, y_train, y_test = train_test_split(word_vectorized, y, test_size = 0.25, random_state=1000) \n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRvSxqBdtdbn",
        "outputId": "b5704e84-2da3-456e-eefe-943ad53adcfe"
      },
      "source": [
        "# LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression # \n",
        "from sklearn.metrics import accuracy_score #\n",
        "# adding training and testing set defining the LinearSVC instance firest to fit the training set in\n",
        "model_lr = LogisticRegression()\n",
        "# fit x and y training set in the model\n",
        "model_lr.fit(X_training, y_train)\n",
        "\n",
        "X_train_prediction=model_lr.predict(X_training)\n",
        "training_data_accuracy=accuracy_score(X_train_prediction, y_train)\n",
        "\n",
        "X_test_prediction=model_lr.predict(X_testing)\n",
        "test_data_accuracy=accuracy_score(X_test_prediction, y_test)\n",
        "\n",
        "print('CountVectorizer - Accuracy score of the training: ',round(training_data_accuracy,3) )\n",
        "print('CountVectorizer - Accuracy score of the test : ',round(test_data_accuracy,3) )"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer - Accuracy score of the training:  0.944\n",
            "CountVectorizer - Accuracy score of the test :  0.897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "99GBOh0pudIw",
        "outputId": "df2b5d39-baf7-482c-d391-552cac9e0763"
      },
      "source": [
        "#example n-gram\n",
        "sentences_n =['this is for testing counting testing training and testing',\n",
        "            'this is second word I can train and say', \n",
        "            'testing, training is very important']\n",
        "\n",
        "txt_vectorize_n=CountVectorizer(ngram_range=(1,2))\n",
        "vectorized_data_n=txt_vectorize_n.fit(sentences_n)\n",
        "print(vectorized_data_n.vocabulary_)\n",
        "print('show get_feature_names : >> ')\n",
        "print(vectorized_data_n.get_feature_names())\n",
        "\n",
        "transformed_data_n=txt_vectorize_n.transform(sentences_n)\n",
        "print('shape: ' ,transformed_data_n.shape) # 3 sentences or documents and 14 words will show (3,14)\n",
        "transformed_data_n.toarray()\n",
        "\n",
        "# show in dataframe where header or column labels is vectorized_data.get_feature_names() and data is transformed_data.toarray()\n",
        "vect_df_n=pd.DataFrame(transformed_data_n.toarray(),columns=vectorized_data_n.get_feature_names())\n",
        "vect_df_n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 20, 'is': 10, 'for': 7, 'testing': 17, 'counting': 5, 'training': 24, 'and': 0, 'this is': 21, 'is for': 11, 'for testing': 8, 'testing counting': 18, 'counting testing': 6, 'testing training': 19, 'training and': 25, 'and testing': 2, 'second': 15, 'word': 29, 'can': 3, 'train': 22, 'say': 14, 'is second': 12, 'second word': 16, 'word can': 30, 'can train': 4, 'train and': 23, 'and say': 1, 'very': 27, 'important': 9, 'training is': 26, 'is very': 13, 'very important': 28}\n",
            "show get_feature_names : >> \n",
            "['and', 'and say', 'and testing', 'can', 'can train', 'counting', 'counting testing', 'for', 'for testing', 'important', 'is', 'is for', 'is second', 'is very', 'say', 'second', 'second word', 'testing', 'testing counting', 'testing training', 'this', 'this is', 'train', 'train and', 'training', 'training and', 'training is', 'very', 'very important', 'word', 'word can']\n",
            "shape:  (3, 31)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>and say</th>\n",
              "      <th>and testing</th>\n",
              "      <th>can</th>\n",
              "      <th>can train</th>\n",
              "      <th>counting</th>\n",
              "      <th>counting testing</th>\n",
              "      <th>for</th>\n",
              "      <th>for testing</th>\n",
              "      <th>important</th>\n",
              "      <th>is</th>\n",
              "      <th>is for</th>\n",
              "      <th>is second</th>\n",
              "      <th>is very</th>\n",
              "      <th>say</th>\n",
              "      <th>second</th>\n",
              "      <th>second word</th>\n",
              "      <th>testing</th>\n",
              "      <th>testing counting</th>\n",
              "      <th>testing training</th>\n",
              "      <th>this</th>\n",
              "      <th>this is</th>\n",
              "      <th>train</th>\n",
              "      <th>train and</th>\n",
              "      <th>training</th>\n",
              "      <th>training and</th>\n",
              "      <th>training is</th>\n",
              "      <th>very</th>\n",
              "      <th>very important</th>\n",
              "      <th>word</th>\n",
              "      <th>word can</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   and  and say  and testing  can  ...  very  very important  word  word can\n",
              "0    1        0            1    0  ...     0               0     0         0\n",
              "1    1        1            0    1  ...     0               0     1         1\n",
              "2    0        0            0    0  ...     1               1     0         0\n",
              "\n",
              "[3 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEEezR5ovq-p",
        "outputId": "a9d6dbc3-1837-4d58-a60c-215081cf0923"
      },
      "source": [
        "# apply ngram on our last data set column cleaned \n",
        "vectorized_ng=CountVectorizer(ngram_range=(2,2))\n",
        "word_training_n= vectorized_ng.fit_transform(df['text_clean'])\n",
        "word_training_n.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7482, 20271)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iif_LDVMwsuf"
      },
      "source": [
        "word_training_n= vectorized_ng.fit_transform(df['text_clean'])\n",
        "y = df['ratings_code'].values\n",
        "from sklearn.model_selection import train_test_split # to split our dtata set into training data and test data\n",
        "# define the training and test sets, 0.2 means test data is %20 of the trained data will stored in the X_test\n",
        "Xn_training, Xn_testing, y_train, y_test = train_test_split(word_training_n, y, test_size = 0.25, random_state=1000) \n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GGRPD3Qxn8b",
        "outputId": "b76ab01a-0352-419c-efe8-cad25e0a029d"
      },
      "source": [
        "# LogisticRegression for ngram\n",
        "from sklearn.linear_model import LogisticRegression # \n",
        "from sklearn.metrics import accuracy_score #\n",
        "# adding training and testing set defining the LinearSVC instance firest to fit the training set in\n",
        "model_lr_ng = LogisticRegression()\n",
        "# fit x and y training set in the model\n",
        "model_lr_ng.fit(Xn_training, y_train)\n",
        "\n",
        "Xn_train_prediction=model_lr_ng.predict(Xn_training)\n",
        "training_data_accuracy_ng=accuracy_score(Xn_train_prediction, y_train)\n",
        "\n",
        "Xn_test_prediction=model_lr_ng.predict(Xn_testing)\n",
        "test_data_accuracy_ng=accuracy_score(Xn_test_prediction, y_test)\n",
        "\n",
        "print('CountVectorizer(ngram) Accuracy score of the training: ',round(training_data_accuracy_ng,3) )\n",
        "print('CountVectorizer(ngram) Accuracy score of the test:',round(test_data_accuracy_ng,3) )"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer(ngram) Accuracy score of the training:  0.989\n",
            "CountVectorizer(ngram) Accuracy score of the test: 0.871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "dYtr8XyOx5DX",
        "outputId": "c5715f4d-f50a-4840-bf1a-ec9e9223923b"
      },
      "source": [
        "# TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect=TfidfVectorizer()\n",
        "#example tf-idf\n",
        "sentences_tfidf =['this is for testing counting testing training and testing',\n",
        "            'this is second word I can train and say', \n",
        "            'testing, training is very important']\n",
        "\n",
        "vectorized_data_tfidf=tfidf_vect.fit(sentences_tfidf)\n",
        "print(vectorized_data_tfidf.vocabulary_)\n",
        "print('show get_feature_names : >> ')\n",
        "print(vectorized_data_tfidf.get_feature_names())\n",
        "\n",
        "transformed_data_tfidf=tfidf_vect.transform(sentences_tfidf)\n",
        "print('shape: ' ,transformed_data_tfidf.shape) # 3 sentences or documents and 14 words will show (3,14)\n",
        "transformed_data_tfidf.toarray()\n",
        "\n",
        "# show in dataframe where header or column labels is vectorized_data.get_feature_names() and data is transformed_data.toarray()\n",
        "vect_df_tfidf=pd.DataFrame(transformed_data_tfidf.toarray(),columns=vectorized_data_tfidf.get_feature_names())\n",
        "vect_df_tfidf"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 9, 'is': 5, 'for': 3, 'testing': 8, 'counting': 2, 'training': 11, 'and': 0, 'second': 7, 'word': 13, 'can': 1, 'train': 10, 'say': 6, 'very': 12, 'important': 4}\n",
            "show get_feature_names : >> \n",
            "['and', 'can', 'counting', 'for', 'important', 'is', 'say', 'second', 'testing', 'this', 'train', 'training', 'very', 'word']\n",
            "shape:  (3, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>can</th>\n",
              "      <th>counting</th>\n",
              "      <th>for</th>\n",
              "      <th>important</th>\n",
              "      <th>is</th>\n",
              "      <th>say</th>\n",
              "      <th>second</th>\n",
              "      <th>testing</th>\n",
              "      <th>this</th>\n",
              "      <th>train</th>\n",
              "      <th>training</th>\n",
              "      <th>very</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.249526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.328096</td>\n",
              "      <td>0.328096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.193779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.748577</td>\n",
              "      <td>0.249526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.249526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.298174</td>\n",
              "      <td>0.392063</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.231559</td>\n",
              "      <td>0.392063</td>\n",
              "      <td>0.392063</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298174</td>\n",
              "      <td>0.392063</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.392063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534093</td>\n",
              "      <td>0.315444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406192</td>\n",
              "      <td>0.534093</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        and       can  counting  ...  training      very      word\n",
              "0  0.249526  0.000000  0.328096  ...  0.249526  0.000000  0.000000\n",
              "1  0.298174  0.392063  0.000000  ...  0.000000  0.000000  0.392063\n",
              "2  0.000000  0.000000  0.000000  ...  0.406192  0.534093  0.000000\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP-xb5FpywVj"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect=TfidfVectorizer()\n",
        "\n",
        "Xtf_training = tfidf_vect.fit_transform(df['text_clean'])\n",
        "y = df['ratings_code'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split # to split our dtata set into training data and test data\n",
        "# define the training and test sets, 0.2 means test data is %20 of the trained data will stored in the X_test\n",
        "Xt_training, Xt_testing, y_train, y_test = train_test_split(Xtf_training, y, test_size = 0.25, random_state=1000) "
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaygxJfd0PXY",
        "outputId": "17338c11-7808-4e4f-92b1-5f2c2e3aad56"
      },
      "source": [
        "# LogisticRegression for tfidf vectorization\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression # \n",
        "from sklearn.metrics import accuracy_score #\n",
        "# adding training and testing set defining the LinearSVC instance firest to fit the training set in\n",
        "model_lr_tf = LinearSVC()\n",
        "# fit x and y training set in the model\n",
        "model_lr_tf.fit(Xt_training, y_train)\n",
        "\n",
        "Xt_train_prediction=model_lr_tf.predict(Xt_training)\n",
        "training_data_accuracy_t=accuracy_score(Xt_train_prediction, y_train)\n",
        "\n",
        "Xt_test_prediction=model_lr_tf.predict(Xt_testing)\n",
        "test_data_accuracy_t=accuracy_score(Xt_test_prediction, y_test)\n",
        "\n",
        "print('TfidfVectorizer - Accuracy score of the training:',round(training_data_accuracy_t,3) )\n",
        "print('TfidfVectorizer - Accuracy score of the test:',round(test_data_accuracy_t,3) )"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer - Accuracy score of the training: 0.977\n",
            "TfidfVectorizer - Accuracy score of the test: 0.905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpX1elcM1ZsJ",
        "outputId": "7d1f76e1-a674-4fe2-bb6c-43d91f2635c7"
      },
      "source": [
        "# data entry test model\n",
        "#========================\n",
        "#input the data for testing the model\n",
        "X_new = [input('please input your text to test : ')]\n",
        "# save the input data in a new data frame\n",
        "X_new_data=pd.DataFrame({0:X_new})\n",
        "\n",
        "#vectorize the inputs and create the training set to use the input data to test from\n",
        "test_vectorized=CountVectorizer()\n",
        "training_features = test_vectorized.fit_transform(df['text_clean'])    \n",
        "test_features = test_vectorized.transform(df['text_clean'])\n",
        "model_test = LinearSVC()\n",
        "model_test.fit(training_features, df['ratings_code'])\n",
        "y_pred = model_test.predict(test_features)\n",
        "\n",
        "#predict the vectorized inputs\n",
        "X_new_test = test_vectorized.transform(X_new_data[0])  \n",
        "prediction=model_test.predict(X_new_test)\n",
        "print(prediction)\n",
        "\n",
        "#'very violent':0,'good':1\n",
        "if (prediction[0]==0):\n",
        "    print('violent')\n",
        "elif (prediction[0]==1):\n",
        "    print('good')\n",
        "else:\n",
        "    print('unable to predict')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "please input your text to test : this is bad\n",
            "[0]\n",
            "violent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv7sYdN2HsDq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}